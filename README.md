# 4D Neural Cognition

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Status: Active](https://img.shields.io/badge/Status-Active-success.svg)]()
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Documentation](https://img.shields.io/badge/docs-comprehensive-brightgreen.svg)](docs/INDEX.md)

> *A revolutionary brain simulation system bridging biological neuroscience with digital computing through four-dimensional neural networks.*

This project implements a 4D brain system that combines biological principles with digital extensions. It simulates neurons in a four-dimensional lattice that can age, die, and reproduce with inheritance of mutated properties. Different brain areas process specific senses â€“ including a novel digital sense for system data and patterns.

**[English](#english-documentation) | [Deutsch](#deutsche-dokumentation)**

---

## ğŸŒŸ Key Features

- **4D Neuron Lattice**: Neurons in an (x, y, z, w) coordinate system
- **Multiple Neuron Models**: LIF, Izhikevich (regular spiking, fast spiking, bursting), with inhibitory neurons
- **Cell Lifecycle**: Aging, death, and reproduction with inherited mutations
- **Brain Areas & Senses**: Vision, Audition, Somatosensory, Taste, Smell, Vestibular, Digital
- **Advanced Plasticity**: Hebbian learning, STDP, weight decay, and homeostatic mechanisms
- **Learning Systems Framework**: Integrated biological and machine learning systems
  - 3 biological/psychological systems (associative, non-associative, operant conditioning)
  - 5 machine learning systems (supervised, unsupervised, reinforcement, transfer, meta-learning)
- **Performance Optimizations**: 
  - Sparse connectivity matrix and time-indexed spike buffer for large-scale simulations
  - GPU acceleration with CUDA for vectorized neuron updates (optional)
  - Multi-core CPU parallelization with spatial partitioning
  - Memory optimization with compression, memory-mapping, and cache optimization
- **Tasks & Evaluation**: Comprehensive benchmark framework for measuring network performance
- **Knowledge Database**: Pre-training and continued learning from stored knowledge
- **Configuration Comparison**: Objectively compare different network configurations
- **Efficient Storage**: JSON for configuration, HDF5 for efficient data persistence with compression
- **Modern Web Interface**: Browser-based interface with real-time visualization and automatic checkpointing
- **Advanced Web Features**:
  - **3D/4D Visualization**: Interactive 3D neuron viewer with 4D projection controls and activity animation
  - **Real-time Analytics**: Spike rate histograms, network statistics, learning curves, and performance metrics
  - **Experiment Management**: Batch parameter modification, parameter sweeps, A/B testing, and version control
  - **Collaboration**: Multi-user support, shared simulations, annotations, and version history
- **Robust & Secure**: Input validation, path sanitization, automatic recovery, rate limiting, and comprehensive error handling
- **Comprehensive Testing**: 753 tests with 71% code coverage, CI/CD pipeline with GitHub Actions
- **Advanced Memory**: Long-term memory consolidation, replay mechanisms, and sleep-like states
- **Attention Systems**: Top-down attention, bottom-up saliency, and winner-take-all circuits

---

## ğŸ“‹ Table of Contents

- [Quick Start](#-quick-start)
- [Documentation](#-documentation)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Contributing](#-contributing)
- [License](#-license)
- [Citation](#-citation)

---

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/Thomas-Heisig/4D-Neural-Cognition.git
cd 4D-Neural-Cognition

# Install dependencies
pip install -r requirements.txt

# Run example simulation
python example.py

# Start web interface
python app.py
# Basic Interface: http://localhost:5000
# Advanced Interface: http://localhost:5000/advanced
```

---

## ğŸ“š Documentation

> **ğŸ“‘ Documentation Hub**: See [DOCUMENTATION.md](DOCUMENTATION.md) for complete overview  
> **ğŸ“– Full Index**: See [docs/INDEX.md](docs/INDEX.md) for detailed navigation

### ğŸš€ Getting Started
- **[User Guide](docs/user-guide/)** - Complete user documentation
  - **[Installation Guide](docs/user-guide/INSTALLATION.md)** - Detailed setup for all platforms
  - **[Quick Start Tutorial](docs/tutorials/QUICK_START_EVALUATION.md)** - Get up and running in 5 minutes
  - **[FAQ](docs/user-guide/FAQ.md)** - Frequently Asked Questions
  - **[Glossary](docs/user-guide/GLOSSARY.md)** - Terminology and definitions

### ğŸ“– Core Documentation

- **[VISION.md](VISION.md)** - Project vision, goals, and roadmap
- **[TODO.md](TODO.md)** - Planned features and task tracking
- **[ISSUES.md](ISSUES.md)** - Known issues and limitations
- **[CHANGELOG.md](CHANGELOG.md)** - Version history and changes

### ğŸ¤ Community

- **[CONTRIBUTING.md](CONTRIBUTING.md)** - How to contribute to the project
- **[CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md)** - Community guidelines
- **[SUPPORT.md](SUPPORT.md)** - How to get help
- **[SECURITY.md](SECURITY.md)** - Security policy

### ğŸ”§ Technical Documentation

- **[API Reference](docs/api/API.md)** - Complete API documentation
- **[Architecture](docs/ARCHITECTURE.md)** - Technical architecture details
- **[Learning Systems](docs/LEARNING_SYSTEMS.md)** - Biological and machine learning framework
- **[Tasks & Evaluation](docs/user-guide/TASKS_AND_EVALUATION.md)** - Benchmark framework guide
- **[Developer Guide](docs/developer-guide/)** - Contributing and development

---

## ğŸ’» Installation

### Simple Installation

```bash
pip install -r requirements.txt
```

For detailed platform-specific instructions, see [Installation Guide](docs/user-guide/INSTALLATION.md).

### Requirements

- Python 3.8+
- NumPy >= 1.20.0
- h5py >= 3.0.0
- Flask >= 2.0.0
- flask-cors >= 3.0.0
- flask-socketio >= 5.0.0
- python-socketio >= 5.0.0

---

## ğŸ¯ Usage

### Web Interface (Recommended)

Start the web application for a user-friendly graphical interface:

```bash
python app.py
```

Then open a browser and navigate to:
- **Basic Interface**: `http://localhost:5000`
- **Advanced Interface**: `http://localhost:5000/advanced`

**Basic Interface Features**:
- ğŸ® **Model Control**: Initialize and configure models
- ğŸ”¥ **Heatmap Visualization**: Real-time display of neural activity
- ğŸ’» **Terminal**: Input/output for sensory data
- ğŸ’¬ **Chat & Operations**: Command-based interaction
- ğŸ“‹ **System Logs**: Real-time logging and monitoring

**Advanced Interface Features**:
- ğŸ¨ **3D/4D Visualization**:
  - Interactive 3D neuron viewer with orbit controls
  - 4D projection controls using stereographic projection
  - Activity animation over time
  - Connection visualization between neurons
  - Multiple color mapping modes (membrane potential, health, age, activity)

- ğŸ“Š **Real-time Analytics**:
  - Spike rate histograms
  - Network statistics (neurons, synapses over time)
  - Learning curves with dual y-axis
  - Performance metrics dashboard (radar charts)
  - Data export functionality

- ğŸ§ª **Experiment Management**:
  - Create and manage experiments
  - Batch parameter modification
  - Parameter sweep tools
  - A/B testing of configurations
  - Experiment comparison and versioning
  - Import/export experiments

- ğŸ‘¥ **Collaborative Features**:
  - Multi-user support with real-time updates
  - Shared simulations
  - Comment and annotation system
  - Version control for experiments
  - Version comparison tools
- ğŸ’¬ **Chat Interface**: Interactive commands
- ğŸ“‹ **Logging**: Complete event logging with automatic rotation
- âš¡ **Training**: Start/stop/step controls with progress tracking
- ğŸ’¾ **Auto-Checkpoint**: Automatic model checkpointing and recovery
- ğŸ”’ **Security**: Input validation and path sanitization

### Command Line

```bash
python example.py
```

### Programmatic Usage

```python
from src.brain_model import BrainModel
from src.simulation import Simulation
from src.senses import feed_sense_input, create_digital_sense_input
import numpy as np

# Load model
model = BrainModel(config_path='brain_base_model.json')

# Initialize simulation
sim = Simulation(model, seed=42)

# Create neurons in areas
sim.initialize_neurons(area_names=['V1_like', 'Digital_sensor'], density=0.1)

# Create synaptic connections
sim.initialize_random_synapses(connection_probability=0.01)

# Prepare sensory input
vision_input = np.random.rand(20, 20) * 10
digital_input = create_digital_sense_input("Hello, World!")

# Run simulation
for step in range(100):
    if step % 10 == 0:
        feed_sense_input(model, 'vision', vision_input)
        feed_sense_input(model, 'digital', digital_input)
    stats = sim.step()
    print(f"Step {step}: {len(stats['spikes'])} spikes")
```

For complete API documentation, see [API Reference](docs/api/API.md).

## Features

- **4D Neuronengitter**: Neuronen in einem (x, y, z, w) Koordinatensystem
- **Mehrere Neuronenmodelle**: LIF, Izhikevich (Regular Spiking, Fast Spiking, Bursting), mit inhibitorischen Neuronen
- **Zell-Lebenszyklus**: Alterung, Tod und Reproduktion mit Vererbung mutierter Eigenschaften
- **Hirnareale & Sinne**: Vision, Audition, Somatosensorik, Geschmack, Geruch, VestibulÃ¤r, Digital
- **Erweiterte PlastizitÃ¤t**: Hebbsches Lernen, STDP, Gewichtszerfall und homÃ¶ostatische Mechanismen
- **Speicherung**: JSON fÃ¼r Konfiguration, HDF5 fÃ¼r effiziente Datenspeicherung (mit Kompression)
- **Web-Frontend**: Modernes Browser-Interface mit Echtzeit-Visualisierung und automatischen Checkpoints
- **Robust & Sicher**: Eingabevalidierung, Pfad-Sanitisierung, automatische Wiederherstellung, Rate Limiting
- **Umfassende Tests**: 753 Tests mit 71% Code-Abdeckung, CI/CD-Pipeline mit GitHub Actions
- **Erweiterte Speichersysteme**: LangzeitgedÃ¤chtnis-Konsolidierung, Replay-Mechanismen, Schlaf-Ã¤hnliche ZustÃ¤nde
- **Aufmerksamkeitssysteme**: Top-down-Aufmerksamkeit, Bottom-up-Salienz, Winner-Take-All-Schaltkreise

## Installation

```bash
pip install -r requirements.txt
```



## Verwendung

### Web-Frontend (empfohlen)

Starten Sie die Web-Anwendung fÃ¼r eine benutzerfreundliche grafische OberflÃ¤che:

```bash
python app.py
```

Ã–ffnen Sie dann einen Browser und navigieren Sie zu `http://localhost:5000`.

Das Frontend bietet:
- ğŸ® **Modell-Steuerung**: Initialisierung und Konfiguration
- ğŸ”¥ **Heatmap-Visualisierung**: Echtzeit-Darstellung von Input-, Hidden- und Output-Layern
- ğŸ’» **Terminal**: Input/Output fÃ¼r sensorische Daten
- ğŸ’¬ **Chat-Interface**: Interaktive Befehle und Operationen
- ğŸ“‹ **Logging**: VollstÃ¤ndige Protokollierung mit automatischer Rotation
- âš¡ **Training**: Start/Stop-Kontrolle mit Fortschrittsverfolgung
- ğŸ’¾ **Auto-Checkpoint**: Automatische Modell-Checkpoints und Wiederherstellung
- ğŸ”’ **Sicherheit**: Eingabevalidierung und Pfad-Sanitisierung

### Kommandozeilen-Beispiel

```bash
python example.py
```

### Programmatische Nutzung

```python
from src.brain_model import BrainModel
from src.simulation import Simulation
from src.senses import feed_sense_input, create_digital_sense_input
import numpy as np

# Modell laden
model = BrainModel(config_path='brain_base_model.json')

# Simulation initialisieren
sim = Simulation(model, seed=42)

# Neuronen in Arealen erstellen
sim.initialize_neurons(area_names=['V1_like', 'Digital_sensor'], density=0.1)

# Synaptische Verbindungen erstellen
sim.initialize_random_synapses(connection_probability=0.01)

# Sensorische Eingabe vorbereiten
vision_input = np.random.rand(20, 20) * 10
digital_input = create_digital_sense_input("Hello, World!")

# Simulation ausfÃ¼hren
for step in range(100):
    if step % 10 == 0:
        feed_sense_input(model, 'vision', vision_input)
        feed_sense_input(model, 'digital', digital_input)
    stats = sim.step()
    print(f"Step {step}: {len(stats['spikes'])} spikes")
```

## ğŸ“ Project Structure

```
4D-Neural-Cognition/
â”œâ”€â”€ ğŸ“„ README.md              # This file
â”œâ”€â”€ ğŸ“„ VISION.md              # Project vision and roadmap
â”œâ”€â”€ ğŸ“„ TODO.md                # Planned features
â”œâ”€â”€ ğŸ“„ ISSUES.md              # Known issues
â”œâ”€â”€ ğŸ“„ CHANGELOG.md           # Version history
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md        # Contribution guidelines
â”œâ”€â”€ ğŸ“„ CODE_OF_CONDUCT.md     # Community guidelines
â”œâ”€â”€ ğŸ“„ LICENSE                # MIT License
â”‚
â”œâ”€â”€ ğŸ“ docs/                  # Technical documentation
â”‚   â”œâ”€â”€ INDEX.md             # Complete documentation index
â”‚   â”œâ”€â”€ ARCHITECTURE.md      # System architecture
â”‚   â”œâ”€â”€ user-guide/          # User documentation
â”‚   â”œâ”€â”€ developer-guide/     # Contributor documentation
â”‚   â”œâ”€â”€ api/                 # API reference
â”‚   â””â”€â”€ tutorials/           # Learning guides
â”‚
â”œâ”€â”€ ğŸ“„ brain_base_model.json  # Base model configuration
â”œâ”€â”€ ğŸ“„ example.py             # CLI example script
â”œâ”€â”€ ğŸ“„ app.py                 # Flask web application
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“ templates/
â”‚   â””â”€â”€ index.html           # Web interface HTML
â”‚
â”œâ”€â”€ ğŸ“ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css        # UI styling
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js           # Frontend JavaScript
â”‚
â”œâ”€â”€ ğŸ“ tests/                 # Test suite
â”‚   â”œâ”€â”€ test_*.py            # Unit tests
â”‚   â”œâ”€â”€ test_integration.py  # Integration tests
â”‚   â””â”€â”€ test_performance.py  # Performance benchmarks
â”‚
â””â”€â”€ ğŸ“ src/                   # Core source code
    â”œâ”€â”€ __init__.py          # Package initialization
    â”œâ”€â”€ brain_model.py       # Neuron & synapse structures
    â”œâ”€â”€ simulation.py        # Main simulation loop
    â”œâ”€â”€ cell_lifecycle.py    # Cell death & reproduction
    â”œâ”€â”€ plasticity.py        # Learning rules (Hebbian, STDP)
    â”œâ”€â”€ neuron_models.py     # Multiple neuron types (LIF, Izhikevich)
    â”œâ”€â”€ senses.py            # Sensory input processing
    â”œâ”€â”€ storage.py           # HDF5/JSON persistence
    â”œâ”€â”€ tasks.py             # Task/benchmark framework
    â”œâ”€â”€ evaluation.py        # Performance evaluation
    â”œâ”€â”€ knowledge_db.py      # Knowledge database system
    â”œâ”€â”€ metrics.py           # Evaluation metrics
    â””â”€â”€ visualization.py     # Data visualization tools
```

---

## âš™ï¸ Configuration

The `brain_base_model.json` contains:

- **lattice_shape**: Size of 4D lattice [x, y, z, w]
- **neuron_model**: LIF parameters (tau_m, v_rest, v_reset, v_threshold)
- **cell_lifecycle**: Lifecycle parameters (max_age, health_decay, mutation rates)
- **plasticity**: Learning parameters (learning_rate, weight_bounds)
- **senses**: Sense configuration with areas and input sizes
- **areas**: Coordinate ranges for each brain area

---

## ğŸ› ï¸ Technology Stack

- **Backend**: Flask (Python web framework)
- **Frontend**: Vanilla JavaScript with Socket.IO
- **Styling**: Modern CSS with dark theme
- **Visualization**: HTML5 Canvas for heatmaps
- **Data Storage**: HDF5 with compression, SQLite for knowledge database
- **Real-time Communication**: WebSocket (Flask-SocketIO)
- **Scientific Computing**: NumPy
- **Testing**: pytest with 408 tests, coverage reporting
- **Code Quality**: pylint, flake8, black, mypy
- **CI/CD**: GitHub Actions with multi-platform testing

---

## ğŸ¤ Contributing

We welcome contributions from the community! Please read our [Contributing Guidelines](CONTRIBUTING.md) to get started.

### Ways to Contribute

- ğŸ› **Report bugs** - See [ISSUES.md](ISSUES.md)
- âœ¨ **Suggest features** - See [TODO.md](TODO.md)
- ğŸ“ **Improve documentation**
- ğŸ”§ **Submit pull requests**
- â­ **Star the repository**

### Development Setup

```bash
# Clone repository
git clone https://github.com/Thomas-Heisig/4D-Neural-Cognition.git
cd 4D-Neural-Cognition

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install development tools
pip install pytest pylint black flake8 mypy

# Run tests (when available)
pytest tests/
```

For detailed contribution guidelines, see [CONTRIBUTING.md](CONTRIBUTING.md).

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2025 Thomas Heisig and Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ“– Citation

If you use this project in your research, please cite:

```bibtex
@software{4d_neural_cognition,
  author = {Heisig, Thomas and Contributors},
  title = {4D Neural Cognition: A Four-Dimensional Brain Simulation System},
  year = {2025},
  url = {https://github.com/Thomas-Heisig/4D-Neural-Cognition},
  version = {1.0.0}
}
```

---

## ğŸŒ Resources

- **GitHub Repository**: https://github.com/Thomas-Heisig/4D-Neural-Cognition
- **Documentation**: [docs/](docs/)
- **Issue Tracker**: GitHub Issues
- **Discussions**: GitHub Discussions

---

## â“ FAQ

**Q: What is the "4th dimension" (w) used for?**  
A: The w-coordinate can represent different modalities, time slices, or abstract organizational principles. It's flexible and can be adapted to your use case.

**Q: Can I run this on GPU?**  
A: Not yet, but GPU acceleration is planned. See [TODO.md](TODO.md) for roadmap.

**Q: How large can models scale?**  
A: Currently tested up to ~50,000 neurons on a standard laptop. Larger models require optimization. See [ISSUES.md](ISSUES.md) for performance limitations.

**Q: Is this biologically accurate?**  
A: It's biologically *inspired*, not a detailed biological simulation. The LIF model and Hebbian plasticity are simplified abstractions.

---

## ğŸ™ Acknowledgments

- Inspired by computational neuroscience research
- Built with open-source technologies
- Thanks to all contributors

---

## ğŸ“ Contact

For questions, suggestions, or collaborations:
- Open an issue on GitHub
- Check [CONTRIBUTING.md](CONTRIBUTING.md) for contribution guidelines

---

<details>
<summary><h2 id="deutsche-dokumentation">ğŸ“ Deutsche Dokumentation</h2></summary>

## Ãœberblick

Dieses Modell implementiert ein 4D-Hirnsystem, das biologische Prinzipien mit digitalen Erweiterungen verbindet. Es simuliert Neuronen in einem vierdimensionalen Gitter, die altern, sterben und sich mit Vererbung mutierter Eigenschaften reproduzieren kÃ¶nnen.

## Features

- **4D Neuronengitter**: Neuronen in einem (x, y, z, w) Koordinatensystem
- **Mehrere Neuronenmodelle**: LIF, Izhikevich, inhibitorische Neuronen
- **Zell-Lebenszyklus**: Alterung, Tod und Reproduktion
- **Hirnareale & Sinne**: Vision, Audition, Somatosensorik, Geschmack, Geruch, VestibulÃ¤r, Digital
- **Erweiterte PlastizitÃ¤t**: Hebbsches Lernen, STDP, Gewichtszerfall
- **Web-Frontend**: Modernes Browser-Interface mit Echtzeit-Visualisierung und Auto-Checkpoints
- **Robust & Sicher**: Eingabevalidierung, automatische Wiederherstellung
- **Umfassende Tests**: 186 Tests, CI/CD-Pipeline

## Installation

```bash
pip install -r requirements.txt
```

## Verwendung

```bash
# Web-Interface starten
python app.py

# Kommandozeilen-Beispiel
python example.py
```

Weitere Details finden Sie in der [englischen Dokumentation](#english-documentation) oben.

</details>

---

*Last Updated: December 2025*  
*Version: 1.0.0*
